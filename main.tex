%\documentclass{article}
%\documentclass[draft]{report}%{article}
\documentclass{report}%{article}
\usepackage{graphicx}
%\usepackage[draft]{graphicx}
\graphicspath{{figs}{notebooks}{.}}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{comment}
\usepackage{color}
\usepackage[acronym]{glossaries}
%\usepackage{alphalph} % For extended alphabetical numbering
\usepackage{appendix}

% \usepackage[%
%filename ,%
%content={no image available}
%]{draftfigure}

\makeglossaries
% \newacronym{label}{acronym}{definition}

\newacronym{LM}{LM}{Light Microscopy}
\newacronym{EM}{EM}{Electron Microscopy}
\newacronym{TEM}{TEM}{Transmission Electron Microscopy}
\newacronym{SEM}{SEM}{Scanning Electron Microscopy}
\newacronym{SPM}{SPM}{Scanning Probe Microscopy}
\newacronym{AFM}{AFM}{Atomic Force Microscopy}
\newacronym{STM}{STM}{Scanning Tunneling Microscope}

\newacronym{ET}{ET}{Electron Tomography}
\newacronym{cryo-ET}{Cryo-ET}{Cryo-Electron Tomography}
\newacronym{OPT}{OPT}{Optical Projection Tomography}
\newacronym{SXT}{STX}{Soft X-ray Tomography}
\newacronym{PAT}{PAT}{PhotoAcoustic Tomography}

\newacronym{GT}{GT}{Ground Truth}

\newacronym{DRV}{DRV}{Discrete Random Variable}

\newacronym{CC}{CC}{Cross-Correlation}
\newacronym{NCC}{NCC}{Normalized Cross-Correlation}
\newacronym{PCC}{PCC}{Pearson Correlation Coefficient}
\newacronym{AC}{AC}{Auto-Correlation}
\newacronym{NAC}{NAC}{Normalized Auto-Correlation}
\newacronym{SNR}{SNR}{Signal-to-Noise Ratio}
\newacronym{PSNR}{PSNR}{Peak \acrshort{SNR}}
\newacronym{SSNR}{SSNR}{Spectral Signal-to-Noise Ratio}
\newacronym{SRV}{SRV}{Stationary Random Variable}
\newacronym{FTDF}{FTDF}{Fourier Transform of a Discrete Function}
\newacronym{DTFT}{DTFT}{Discrete Time Fourier Transform}
\newacronym{IDTFT}{IDTFT}{Inverse Discrete Time Fourier Transform}
\newacronym{DFT}{DFT}{Discrete Fourier Transform}
\newacronym{IDFT}{IDFT}{Inverse Discrete Fourier Transform}
\newacronym{FFT}{FFT}{Fast Fourier Transform}
\newacronym{IFFT}{IFFT}{Inverse Fast Fourier Transform}
\newacronym{PS}{PS}{Power Spectrum}
\newacronym{PSD}{PSD}{Power Spectral Density}
\newacronym{CPSD}{CPSD}{Cross-Power Spectral Density}
\newacronym{MAD}{MAD}{Mean Absolute Deviation}

\newacronym{AWG}{AWG}{Additive White Gaussian}
\newacronym{PDF}{PDF}{Probability Density Function}
\newacronym{PMF}{PMF}{Probability Mass Function}
\newacronym{PMD}{PMD}{Probability Mass Distribution}
\newacronym{MPG}{MPG}{Mixed Poisson-Gaussian}

\newacronym{FSC}{FSC}{\href{https://en.wikipedia.org/wiki/Fourier_shell_correlation}
{Fourier Shell Correlation}}
\newacronym{SFRC}{SFRC}{Self Fourier Ring Correlation}
\newacronym{FRC}{FRC}{Fourier Ring Correlation}
\newacronym{FC}{FC}{Fourier Correlation}
\newacronym{SFC}{SFC}{Self Fourier Correlation}

\newacronym{DOF}{DOF}{Dense Optical Flow}
\newacronym{EOS}{EOS}{Even-Odd Splitting}
\newacronym{CBS}{CBS}{ChessBoard Splitting}
\newacronym{ICBS}{ICBS}{Interpolated \acrshort{CBS}}
\newacronym{SCBS}{SCBS}{Subsampled \acrshort{CBS}}
\newacronym{SPRS}{SPRS}{Structure Preserving Random Shuffling}
\newacronym{TRPR}{TRPR}{TriS-D Random Pixel Resampling}

\newacronym{MSE}{MSE}{Mean Square Error}
\newacronym{RMSE}{RMSE}{Root \acrshort{MSE}}
\newacronym{SSIM}{SSIM}{Structural Similarity Index Measure }
\newacronym{MS-SSIM}{MS-SSIM}{Multi-Scale \acrshort{SSIM}}
\newacronym{LPIPS}{LPIPS}{Learned Perceptual Image Patch Similarity}
\newacronym{NIQE}{NIQE}{Natural Image Quality Evaluator}
\newacronym{CS}{CS}{Cosine Similarity}

\newacronym{CLT}{CLT}{Central Limit Theorem}
\newacronym{GAT}{GAT}{Generalized Anscombe Transform}
\newacronym{VST}{VST}{Variance-Stabilizing Transform}
\newacronym{MNI}{MNI}{Mean of Noisy Instances}

\newacronym{GF}{GF}{Gaussian Filtering}
\newacronym{WF}{WF}{Wiener Filtering}
\newacronym{GD}{GD}{Gaussian Denoising}
\newacronym{TF}{TF}{Transfer Function}
\newacronym{LTI}{LTI}{Linear Time-Invariant}
\newacronym{NoO}{NoO}{Number of Operations}
\newacronym{IIR}{IIR}{Infinite Impulse Response}
\newacronym{FIR}{IIR}{Finite Impulse Response}

\newacronym{CNN}{CNN}{Convolutional Neural Network}

\newacronym{BM3D}{BM3D}{Block-Matching and 3D filtering}
\newacronym{DnCNN}{DnCNN}{Denoising \acrshort{CNN}}

\title{Denoising in Microscopy Imaging}

\author{Vicente González-Ruiz and José Jesús Fernández Rodríguez}

\begin{document}
\maketitle
\tableofcontents

\section*{Definitions and notation}
%{{{

\begin{tabular}{ll}
  $x$ & A scalar value (e.g., a value of a pixel of a grayscale image) \\
  $s(t)$ & A (continuous) signal as a function of time \\
  $s[n]$ & A discrete signal (only) defined at instants of time $tn, n\in\mathcal{Z}, t>0$ \\
  $\mathbf{s}$ & A digital (discrete and finite) signal (e.g., an image) \\
  $\mathbf{s}_{i}$ & The $i$-th element of $\mathbf{s}=\{\mathbf{s}_{i}\}_{i=0}^{N-1}=\{\mathbf{s}_{i}\}$ \\
  %$A[b]$ & The $b$-th element of the sampled version of $A(b)$ \\
  $\{i\}$ & The set $i$ \\
  $\mathbf{s}_{\{i\}}$ & The elements of $\mathbf{s}$ with indices $\{i\}$ \\
  $\mathbf{s}_{[i]}$ & A window of samples of $\mathbf{s}$ centered at the $i$-th sample \\
  $\mathbf{s}_{\href{https://numpy.org/doc/stable/user/basics.indexing.html#slicing-and-striding}{y,:}}$ & The $y$-th row of the image $\mathbf{s}$ \\
  $\mathbf{s}_{:,x}$ & The $x$-th column of the image $\mathbf{s}$ \\
  $\mathbf{s}_{y,x}$ & The pixel $(y,x)$ of the image $\mathbf{s}$ \\
  %$\mathbf{x}^{(i)}$ & The $i$-th real-noisy instance of the signal $\mathbf{x}$ \\
  %$\mathbf{s}^{()}$ & An instance of $\mathbf{s}$, possibly noisy \\
  $\mathbf{s}^{(i)}$ & The $i$-th instance of the signal $\mathbf{s}$ \\
  $\tilde{\mathbf{s}}^{(I)}$ & Approximation to $\mathbf{s}$ using $I$ instances \\ 
  $\overline{\mathbf{s}}$ & A mean of the samples of $\mathbf{s}$ \\ 
  $\href{https://docs.python.org/3/library/functions.html#len}{\text{len}}(\mathbf{s})$ & $=\mathbf{s}.\href{https://numpy.org/doc/stable/reference/generated/numpy.ndarray.size.html}{\mathsf{size}}$ Number of elements in $\mathbf{s}$ \\
  $\href{https://numpy.org/doc/stable/reference/generated/numpy.shape.html}{\text{shape}}(\mathbf{s})$ & ($=\mathbf{s}.{\mathsf{shape}}$) Shape of $\mathbf{s}$ \\
  $\text{rank}(\mathbf{s})$ & ($=\mathbf{s}.\mathsf{rank}=\text{len}(\mathbf{s}.\mathsf{shape})$) Dimensionality of $\mathbf{s}$ \\
  $\mathsf{\href{https://docs.python.org/3/library/functions.html\#func-range}{range}}(s)$ & $=\{0, 1, \cdots, s-1\}$ \\
  $\mathsf{\href{https://numpy.org/doc/stable/reference/generated/numpy.zeros_like.html}{zeros\_like}}(\mathbf{s})$ & $=\{0\}_{i=0}^{\mathbf{s}.\mathsf{size}-1}$ \\
  % $|\mathbf{X}_i|$ & The absolute value of $\mathbf{X}_i$ \\
  $\alpha\mathbf{s}$ & $=\{\alpha\mathbf{s}_i\}$ (scalar multiplication) \\
  $\mathbf{x}+\mathbf{y}$ & $=\{\mathbf{x}_i + \mathbf{y}_i\}$ (Hadamard addition) \\ 
  $\mathbf{x}\mathbf{y}$ & $=\{\mathbf{x}_i\mathbf{y}_i\}$ (Hadamard product) \\ 
  $\mathcal{N}$ & The normal distribution \\ 
  $\mathcal{P}$ & The Poisson distribution \\
  $\mathbf{x}\sim\mathcal{N}$ & The elements of $\mathbf{x}$ follows a normal distribution \\
  $\mathbf{x}_{\mathcal{N}}$ & The same as $\mathbf{x}\sim\mathcal{N}$ \\
  $\Pr(\mathbf{x}=a)$ & Probability that a $\mathbf{x}_i$ takes the value $a$ \\
  $\Pr(\mathbf{x}=a, \mathbf{y}=b)$ & $\Pr(\mathbf{x}=a)$ and $\Pr(\mathbf{y}=b)$ (joint probability)  \\
  $\text{Su}(\mathbf{x})$ & $=\{x\in\mathbb{R}|\Pr(\mathbf{x}=x)>0\}$ (support of $\mathbf{x}$)\\
  $\Pr(A|B)$ & Conditional probability of $A$ given $B$ \\
  $\mathbb{E}(\mathbf{s})$ & Expectation of $\mathbf{s}$ \\
  $\mathbb{V}(\mathbf{s})$ & Variance of $\mathbf{s}$ \\
  $||\mathbf{s}||_2$ & $L_2$ norm of $\mathbf{s}$ \\
  $f_s$ & Sampling frequency \\
  $\mathcal{F}$ & The (forward) Fourier transform ($\mathcal{F}(\mathbf{s})=\mathbf{S}$) (see Section~\ref{sec:Fourier_transform})\\
  $\mathcal{F}^{-1}$ & The inverse Fourier transform ($\mathcal{F}^{-1}(\mathbf{S})=\mathbf{s}$)  (see Section~\ref{sec:Fourier_transform})\\
  $\cdot^*$ & the complex conjugate of $\cdot$ \\
  $\mathbf{x}*\mathbf{y}$ & $=\mathcal{F}^{-1}(\mathcal{F}(\mathbf{x})\mathcal{F}(\mathbf{y}))=\mathcal{F}^{-1}(\mathbf{X}\mathbf{Y})$ (convolution) \\
  $A(b)$ & $A$ depends on (parameter) $b$ \\
  $A.b$ & The $b$ component of the data structure $A$ \\
  $(A)b$ & First $A$, then $b$ \\
  $E(\mathbf{s})$ & Energy of $\mathbf{s}$ (see Section~\ref{sec:energy_signal}) \\
  $P(\mathbf{s})$ & Power of $\mathbf{s}$ (see Section~\ref{sec:power_signal}) \\
  $\text{PS}(\mathbf{s})$ & Power spectrum of $\mathbf{s}$ (see Section~\ref{sec:power_spectrum}) \\
  $\text{PSD}(\mathbf{s})$ & Power spectral density of $\mathbf{s}$ (see Section~\ref{sec:PSD}) \\
  $\text{CC}(\mathbf{x},\mathbf{y})$ & Cross-correlation between $\mathbf{x}$ and $\mathbf{y}$ (see Section~\ref{sec:cross-correlation}) \\
  $\text{NCC}(\mathbf{x},\mathbf{y})$ & Normalized cross-correlation between $\mathbf{x}$ and $\mathbf{y}$ (see Section~\ref{sec:cross-correlation}) \\
  $\mathbf{a}\bot \mathbf{b}$ & $\mathbf{a}$ and $\mathbf{b}$ are orthogonal or independent                                
\end{tabular}

%}}}

\input{intro}
\input{discrete_signals}
\input{quantization}
\input{statistics}
\input{noise}
\input{distortion_metrics}
\input{MNI}
\input{GF}

% \chapter{Beltrami flow}
% Parece que se usa en AND, pero no se bien cómo.

%\chapter{Median filter}

%\chapter{Bilateral filter}

\input{WF}

% \chapter{Anisotropic Non-linear Diffusion (AND)}

% \chapter{PURE-LET}
%{{{

% . Luisier, T. Blu, and M. Unser. Image denoising in mixed
% PoissonGaussian noise. IEEE Transactions on Image Pro-
% cessing, 20(3):696–708, 2011.

%}}}

%  \chapter{Non Local Means (NLM)}
%{{{

% https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-14-2
% A. Buades, B. Coll, and J.-M. Morel. A non-local algorithm
% for image denoising. In CVPR, 2005.

%}}}

% \chapter{BM3D/BM4D}
%{{{

% K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Image
% denoising by sparse 3-D transform-domain collaborative
% filtering. IEEE Transactions on Image Processing, 16(8):2080–2095, 2007.
%https://pypi.org/project/bm4d/#files

%}}}

% \chapter{K-SVD}
%{{{

% M. Aharon, M. Elad, and A. Bruckstein. K-SVD: An algorithm for
% designing overcomplete dictionaries for sparse
% representation. IEEE Transactions on Signal Processing,
% 54(11):4311–4322, 2006.

%}}}

% \chapter{EPLL}
%{{{

% D. Zoran and Y. Weiss. From learning models of natural
% image patches to whole image restoration. In ICCV, 2011.

%}}}

% \chapter{WNNM}
%{{{

% S. Gu, L. Zhang, W. Zuo, and X. Feng. Weighted nuclear
% norm minimization with application to image denoising. In
% CVPR, 2014.

%}}}

% \chapter{The U-Net}
% \chapter{N2V}
%{{{

% A. Krull, T.-O. Buchholz, and F. Jug, “Noise2void-learning denoising
% from single noisy images,” in Proceedings of the IEEE/CVF conference
% on computer vision and pattern recognition, 2019, pp. 2129–2137.

%}}}

%\chapter{Pixel2Pixel}
%https://ieeexplore.ieee.org/abstract/document/10908805 

%\chapter{DnCNN}
% K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Be-
% yond a Gaussian denoiser: Residual learning of deep CNN
% for image denoising. IEEE Transactions on Image Process-
% ing, 26(7):3142–3155, 2017.

% \chapter{FFDNet}
% K. Zhang, W. Zuo, and L. Zhang. Ffdnet: Toward a fast
% and flexible solution for CNN based image denoising. IEEE
% Transactions on Image Processing, 2018.

% \chapter{CBDNet}
% S. Guo, Z. Yan, K. Zhang, W. Zuo, and L. Zhang. Toward
% convolutional blind denoising of real photographs. In CVPR,
% 2019.

% \chapter{UDNet}
% S. Lefkimmiatis. Universal denoising networks: A novel
% cnn-based network architecture for image denoising. In
% CVPR, 2018.

% T. Pl¨otz and S. Roth. Neural nearest neighbors networks. In
% NIPS, 2018.

%\chapter{Noise2Noise}
% . Lehtinen, J. Munkberg, J. Hasselgren, S. Laine, T. Kar-
% ras, M. Aittala, and T. Aila. Noise2noise: Learning image
% restoration without clean data. In ICML, 2018.

%\chapter{Adapted RCAN (as denoiser)}

% Used in TriS-D, were the last upscaling module is removed to keep
% the spatial resolution \cite{ma2025spatiotemporal}.

% Y. Zhang, K. Li, K. Li, L. Wang, B. Zhong, and Y. Fu, “Image super-
% resolution using very deep residual channel attention networks,” in
% European Conference on Computer Vision (ECCV), 2018.

\input{SPGD}
\input{machine_learning}
\input{Cryo-CARE}

%\chapter{2D Random Shuffing Volume Denoising (2D-RSVD)}

%\chapter{3D Random Shuffling Volume Denoising (3D-RSVD)}


\input{comparative}

\appendix

% Redefine the appendix numbering to use alphalph's extended alphabet
%\makeatletter
%\renewcommand*{\thesection}{%
%  \AlphAlph{\value{section}}%
%}
%\makeatother

%{{{




%}}}

\begin{appendix}

\chapter{Images with \gls{GT}}
\label{sec:images}  
  
\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_FISH.ipynb}{\includegraphics{Confocal_FISH.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_FISH_noisy.ipynb}{\includegraphics{Confocal_FISH_noisy.pdf}}
  \caption{Confocal FISH \cite{zhang2019poisson}.\label{fig:Confocal_FISH}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_MICE.ipynb}{\includegraphics{TwoPhoton_MICE.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_MICE_noisy.ipynb}{\includegraphics{TwoPhoton_MICE_noisy.pdf}}
  \caption{Two-photons MICE \cite{zhang2019poisson}.\label{fig:TwoPhoton_MICE}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_MICE.ipynb}{\includegraphics{Confocal_MICE.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_MICE_noisy.ipynb}{\includegraphics{Confocal_MICE_noisy.pdf}}
  \caption{Confocal MICE \cite{zhang2019poisson}.\label{fig:Confocal_MICE}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE_noisy.pdf}}
  \caption{Confocal BPAE \cite{zhang2019poisson}.\label{fig:Confocal_BPAE}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE_R.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE_noisy_R.pdf}}
  \caption{Confocal BPAE (red channel) \cite{zhang2019poisson}.\label{fig:Confocal_BPAE_R}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE_G.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE_noisy_G.pdf}}
  \caption{Confocal BPAE (green channel) \cite{zhang2019poisson}.\label{fig:Confocal_BPAE_G}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE_B.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/Confocal_BPAE.ipynb}{\includegraphics{Confocal_BPAE_noisy_B.pdf}}
  \caption{Confocal BPAE (blue channel) \cite{zhang2019poisson}.\label{fig:Confocal_BPAE_B}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE_noisy.pdf}}
  \caption{TwoPhoton BPAE \cite{zhang2019poisson}.\label{fig:TwoPhoton_BPAE}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE_R.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE_noisy_R.pdf}}
  \caption{TwoPhoton BPAE (red channel) \cite{zhang2019poisson}.\label{fig:TwoPhoton_BPAE_R}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE_G.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE_noisy_G.pdf}}
  \caption{TwoPhoton BPAE (green channel) \cite{zhang2019poisson}.\label{fig:TwoPhoton_BPAE_G}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE_B.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/TwoPhoton_BPAE.ipynb}{\includegraphics{TwoPhoton_BPAE_noisy_B.pdf}}
  \caption{TwoPhoton BPAE (blue channel) \cite{zhang2019poisson}.\label{fig:TwoPhoton_BPAE_B}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE_noisy.pdf}}
  \caption{WideField BPAE \cite{zhang2019poisson}.\label{fig:WideField_BPAE}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE_R.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE_noisy_R.pdf}}
  \caption{WideField BPAE (red channel) \cite{zhang2019poisson}.\label{fig:WideField_BPAE_R}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE_G.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE_noisy_G.pdf}}
  \caption{WideField BPAE (green channel) \cite{zhang2019poisson}.\label{fig:WideField_BPAE_G}}
\end{figure}

\begin{figure}[h]
  \centering
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE_B.pdf}}
  \href{https://nbviewer.org/github/vicente-gonzalez-ruiz/denoising/blob/main/notebooks/WideField_BPAE.ipynb}{\includegraphics{WideField_BPAE_noisy_B.pdf}}
  \caption{WideField BPAE (blue channel) \cite{zhang2019poisson}.\label{fig:WideField_BPAE_B}}
\end{figure}

\end{appendix}

\printglossary[type=\acronymtype]

\bibliographystyle{plain}
\bibliography{signal_processing,image_processing,microscopy,denoising,motion_estimation,image_compression,statistics}

\end{document}